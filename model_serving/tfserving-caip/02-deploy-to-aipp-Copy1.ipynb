{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TF Serving with AI Platform Prediction Custom Containers (Beta_\n",
    "\n",
    "This notebook demonstrates how to deploy a TensorFlow 2.x model using AI Platform Prediction Custom Containers (Beta) and TensorFlow Serving.\n",
    "\n",
    "\n",
    "For the sake of the demonstration, this notebook uses the custom serving module developed in the `01-prepare-for-serving.ipynb` notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import google.auth\n",
    "\n",
    "from google.auth.credentials import Credentials\n",
    "from google.auth.transport.requests import AuthorizedSession\n",
    "\n",
    "from typing import List, Optional, Text, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment\n",
    "\n",
    "This notebook was tested on **AI Platform Notebooks** using the standard TF 2.2 image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the model store path\n",
    "\n",
    "Set the `SAVED_MODEL_PATH` to the GCS location of the `SavedModel` created in the `01-prepare-for-serving.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODEL_PATH = 'gs://mlops-dev-workspace/models/resnet_serving'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push the TF Serving container to the local GCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , project_id = google.auth.default()\n",
    "\n",
    "cpu_image_name = 'gcr.io/{}/tensorflow_serving:latest-cpu'.format(project_id)\n",
    "gpu_image_name = 'gcr.io/{}/tensorflow_serving:latest-gpu'.format(project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker pull tensorflow/serving:latest\n",
    "!docker pull tensorflow/serving:latest-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag tensorflow/serving:latest {cpu_image_name}\n",
    "!docker tag tensorflow/serving:latest-gpu {gpu_image_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker push {cpu_image_name}\n",
    "!docker push {gpu_image_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper class that wraps AI Platform Prediction Alpha REST API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIPPClient(object):\n",
    "    \"\"\"\n",
    "    A utility class that wraps AI Platform Prediction Alpha REST API.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, service_endpoint):\n",
    "        self._service_endpoint = service_endpoint\n",
    "        credentials, _ = google.auth.default()\n",
    "        self._authed_session = AuthorizedSession(credentials)\n",
    "\n",
    "    def list_models(self, project_id: str) -> dict:\n",
    "        \"\"\"\n",
    "        Lists model resources in a project.\n",
    "        \"\"\"\n",
    "    \n",
    "        url = '{}/v1/projects/{}/models/'.format(self._service_endpoint, project_id)\n",
    "\n",
    "        response = self._authed_session.get(url)\n",
    "    \n",
    "        return response.json()\n",
    "\n",
    "    def get_model(self, project_id: str, model_name: str) -> dict:\n",
    "        \"\"\"\n",
    "        Retrieves model metadata.\n",
    "        \"\"\"\n",
    "    \n",
    "        url = '{}/v1/projects/{}/models/{}'.format(self._service_endpoint, project_id, model_name)\n",
    "\n",
    "        response = self._authed_session.get(url)\n",
    "    \n",
    "        return response.json()\n",
    "    \n",
    "    \n",
    "    def create_model(self, project_id: str, model_name: str) -> dict:\n",
    "        \"\"\"\n",
    "        Creates a model resource.\n",
    "        \"\"\"\n",
    "    \n",
    "        url = '{}/v1/projects/{}/models/'.format(self._service_endpoint, project_id)\n",
    "\n",
    "        request_body = {\n",
    "            \"name\": model_name\n",
    "        }\n",
    "\n",
    "    \n",
    "        response = self._authed_session.post(url, data=json.dumps(request_body))\n",
    "    \n",
    "        return response.json()\n",
    "\n",
    "\n",
    "    def delete_model(self, project_id: str, model_name: str) -> dict:\n",
    "        \"\"\"\n",
    "        Deletes a model resource.\n",
    "        \"\"\"\n",
    "    \n",
    "        url = '{}/v1/projects/{}/models/{}'.format(self._service_endpoint, project_id, model_name)\n",
    "\n",
    "    \n",
    "        response = self._authed_session.delete(url)\n",
    "\n",
    "        return response.json()\n",
    "\n",
    "\n",
    "    def create_model_version(\n",
    "        self,\n",
    "        project_id: str, \n",
    "        model_name: str, \n",
    "        version_name: str,\n",
    "        model_gcs_path: str,\n",
    "        machine_type: str,\n",
    "        serving_image: str,\n",
    "        gpu_count: int=0,\n",
    "        gpu_type: str=None,\n",
    "        enable_batching=False,)-> dict:\n",
    "        \"\"\"\n",
    "        Creates a model version resource.\n",
    "        \"\"\"\n",
    "    \n",
    "        url = '{}/v1/projects/{}/models/{}/versions'.format(self._service_endpoint, project_id, model_name)\n",
    "        \n",
    "        args = [\"--rest_api_port=8080\",\n",
    "                \"--model_name={}\".format(model_name),\n",
    "                \"--model_base_path=$(AIP_STORAGE_URI)\"]\n",
    "        \n",
    "        if enable_batching:\n",
    "            args.append([\n",
    "                \"--enable_batching\",\n",
    "                \"--batching_parameters_file=$(AIP_STORAGE_URI)/batching.pbtxt\"\n",
    "            ])\n",
    "    \n",
    "        request_body = {\n",
    "            \"name\": version_name,\n",
    "            \"deployment_uri\": model_gcs_path,\n",
    "            \"machine_type\": machine_type,\n",
    "            \"container\": {\n",
    "                \"image\": serving_image,\n",
    "                \"args\": args\n",
    "            },\n",
    "            \"routes\": {\n",
    "                \"predict\": \"/v1/models/{}:predict\".format(model_name),\n",
    "                \"health\": \"/v1/models/{}\".format(model_name)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if gpu_count > 0:\n",
    "            accelerator_config = {\n",
    "                \"count\": gpu_count,\n",
    "                \"type\": gpu_type\n",
    "            }\n",
    "            request_body[\"accelerator_config\"] = accelerator_config\n",
    "            \n",
    "    \n",
    "        response = self._authed_session.post(url, data=json.dumps(request_body))\n",
    "\n",
    "        return response.json()\n",
    "\n",
    "\n",
    "    def get_model_version(self, project_id: str, model_name: str, version_name: str)-> dict:\n",
    "        \"\"\"\n",
    "        Creates a model version.\n",
    "        \"\"\"\n",
    "    \n",
    "        url = '{}/v1/projects/{}/models/{}/versions/{}'.format(self._service_endpoint, project_id, model_name, version_name)\n",
    "\n",
    "        response = self._authed_session.get(url)\n",
    "\n",
    "        return response.json()\n",
    "\n",
    "\n",
    "    def delete_model_version(self, project_id: str, model_name: str, version_name: str)-> dict:\n",
    "        \"\"\"\n",
    "        Creates a model version.\n",
    "        \"\"\"\n",
    "    \n",
    "        url = '{}/v1/projects/{}/models/{}/versions/{}'.format(self._service_endpoint, project_id, model_name, version_name)\n",
    "\n",
    "        response = self._authed_session.delete(url)\n",
    "\n",
    "        return response.json()\n",
    "\n",
    "\n",
    "    def list_model_versions(self, project_id: str, model_name: str)-> dict:\n",
    "        \"\"\"\n",
    "        Lists model versions.\n",
    "        \"\"\"\n",
    "    \n",
    "        url = '{}/v1/projects/{}/models/{}/versions'.format(self._service_endpoint, project_id, model_name)\n",
    "\n",
    "        response = self._authed_session.get(url)\n",
    "\n",
    "        return response.json()\n",
    "\n",
    "\n",
    "    def call_predict(\n",
    "        self,\n",
    "        project_id:str, \n",
    "        model_name: str, \n",
    "        version_name: str, \n",
    "        signature: str,\n",
    "        instances: list) -> dict:\n",
    "        \"\"\"\n",
    "        Invokes the predict method on the specified signature.\n",
    "        \"\"\"\n",
    "    \n",
    "        url = '{}/v1/projects/{}/models/{}/versions/{}:predict'.format(self._service_endpoint, project_id, model_name, version_name)    \n",
    "    \n",
    "        request_body = {\n",
    "            'signature_name': signature,\n",
    "            'instances': encoded_images\n",
    "        }\n",
    "    \n",
    "        response = self._authed_session.post(url, data=json.dumps(request_body))\n",
    "\n",
    "        return response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all models in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_endpoint = 'https://alpha-ml.googleapis.com'\n",
    "\n",
    "client = AIPPClient(service_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [{'name': 'projects/mlops-dev-env/models/ResNet101',\n",
       "   'regions': ['us-central1'],\n",
       "   'etag': 'a9Zb+va/g8Y='}]}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_models(project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': {'code': 409,\n",
       "  'message': 'Field: model.name Error: A model with the same name already exists.',\n",
       "  'status': 'ALREADY_EXISTS',\n",
       "  'details': [{'@type': 'type.googleapis.com/google.rpc.BadRequest',\n",
       "    'fieldViolations': [{'field': 'model.name',\n",
       "      'description': 'A model with the same name already exists.'}]}]}}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'ResNet101'\n",
    "\n",
    "client.create_model(project_id, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the model's info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/mlops-dev-env/models/ResNet101',\n",
       " 'regions': ['us-central1'],\n",
       " 'etag': 'a9Zb+va/g8Y='}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_model(project_id, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_model_versions(project_id, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the batch config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "batching_config = 'batching.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting batching.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {batching_config}\n",
    "\n",
    "max_batch_size { value: 128 }\n",
    "batch_timeout_micros { value: 150000 }\n",
    "max_enqueued_batches { value: 16 }\n",
    "num_batch_threads { value: 8 }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy the batch config file to the model's folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://batching.pbtxt [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  136.0 B/  136.0 B]                                                \n",
      "Operation completed over 1 objects/136.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp {batching_config} {SAVED_MODEL_PATH}/{batching_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "max_batch_size { value: 128 }\n",
      "batch_timeout_micros { value: 150000 }\n",
      "max_enqueued_batches { value: 16 }\n",
      "num_batch_threads { value: 8 }\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat {SAVED_MODEL_PATH}/batching.pbtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provision the model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/mlops-dev-env/operations/create_ResNet101_batching_150-1597353807248',\n",
       " 'metadata': {'@type': 'type.googleapis.com/google.cloud.ml.v1.OperationMetadata',\n",
       "  'createTime': '2020-08-13T21:23:28Z',\n",
       "  'operationType': 'CREATE_VERSION',\n",
       "  'modelName': 'projects/mlops-dev-env/models/ResNet101',\n",
       "  'version': {'name': 'projects/mlops-dev-env/models/ResNet101/versions/batching_150',\n",
       "   'deploymentUri': 'gs://mlops-dev-workspace/models/resnet_serving',\n",
       "   'createTime': '2020-08-13T21:23:27Z',\n",
       "   'etag': 'n65JqJRjAcI=',\n",
       "   'machineType': 'n1-standard-8',\n",
       "   'acceleratorConfig': {'count': '1', 'type': 'NVIDIA_TESLA_P4'},\n",
       "   'container': {'image': 'gcr.io/mlops-dev-env/tensorflow_serving:latest-gpu',\n",
       "    'args': ['--rest_api_port=8080',\n",
       "     '--model_name=ResNet101',\n",
       "     '--model_base_path=$(AIP_STORAGE_URI)',\n",
       "     '--enable_batching',\n",
       "     '--batching_parameters_file=$(AIP_STORAGE_URI)/batching.pbtxt']},\n",
       "   'routes': {'predict': '/v1/models/ResNet101:predict',\n",
       "    'health': '/v1/models/ResNet101'}}}}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version_name = 'batching_150'\n",
    "image_name = gpu_image_name\n",
    "machine_type = 'n1-standard-8'\n",
    "gpu_count = 1\n",
    "gpu_type = 'NVIDIA_TESLA_P4'\n",
    "enable_batching = True\n",
    "\n",
    "client.create_model_version(\n",
    "    project_id=project_id, \n",
    "    model_name=model_name,\n",
    "    version_name=version_name,\n",
    "    model_gcs_path=SAVED_MODEL_PATH,\n",
    "    machine_type=machine_type,\n",
    "    serving_image=image_name,\n",
    "    gpu_count=gpu_count,\n",
    "    gpu_type=gpu_type,\n",
    "    enable_batching=enable_batching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the deployment status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/mlops-dev-env/models/ResNet101/versions/batching_150',\n",
       " 'isDefault': True,\n",
       " 'deploymentUri': 'gs://mlops-dev-workspace/models/resnet_serving',\n",
       " 'createTime': '2020-08-13T21:23:27Z',\n",
       " 'state': 'READY',\n",
       " 'etag': 'HT7qYps2w28=',\n",
       " 'machineType': 'n1-standard-8',\n",
       " 'acceleratorConfig': {'count': '1', 'type': 'NVIDIA_TESLA_P4'},\n",
       " 'container': {'image': 'gcr.io/mlops-dev-env/tensorflow_serving:latest-gpu',\n",
       "  'args': ['--rest_api_port=8080',\n",
       "   '--model_name=ResNet101',\n",
       "   '--model_base_path=$(AIP_STORAGE_URI)',\n",
       "   '--enable_batching',\n",
       "   '--batching_parameters_file=$(AIP_STORAGE_URI)/batching.pbtxt']},\n",
       " 'routes': {'predict': '/v1/models/ResNet101:predict',\n",
       "  'health': '/v1/models/ResNet101'}}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_model_version(project_id, model_name, version_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model's versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now run inference by invoking the TF Serving `Predict` API.\n",
    "\n",
    "Refer to the [TF Serving REST API Reference](https://www.tensorflow.org/tfx/serving/api_rest) for more information about the API format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'locust/locust-image/test_images'\n",
    "raw_images = [tf.io.read_file(os.path.join(image_folder, image_path)).numpy()\n",
    "         for image_path in os.listdir(image_folder)]\n",
    "\n",
    "encoded_images = [{'b64': base64.b64encode(image).decode('utf-8')} for image in raw_images]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call the `predict` endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'labels': ['military uniform',\n",
       "    'suit',\n",
       "    'Windsor tie',\n",
       "    'pickelhaube',\n",
       "    'bow tie'],\n",
       "   'probabilities': [0.940013826,\n",
       "    0.0485324822,\n",
       "    0.00640657172,\n",
       "    0.00201301626,\n",
       "    0.000604337547]},\n",
       "  {'labels': ['Egyptian cat', 'tiger cat', 'tabby', 'lynx', 'Siamese cat'],\n",
       "   'probabilities': [0.827052057,\n",
       "    0.131283119,\n",
       "    0.0410555713,\n",
       "    0.0005708182,\n",
       "    1.89249167e-05]}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature = 'serving_preprocess'\n",
    "\n",
    "client.call_predict(\n",
    "    project_id=project_id, \n",
    "    model_name=model_name, \n",
    "    version_name=version_name, \n",
    "    signature=signature,\n",
    "    instances=encoded_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete model version and model\n",
    "#### List model versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'versions': [{'name': 'projects/mlops-dev-env/models/ResNet101/versions/batching_100',\n",
       "   'isDefault': True,\n",
       "   'deploymentUri': 'gs://mlops-dev-workspace/models/resnet_serving',\n",
       "   'createTime': '2020-08-13T19:00:51Z',\n",
       "   'lastUseTime': '2020-08-13T21:22:27Z',\n",
       "   'state': 'READY',\n",
       "   'etag': 'MbwMKzLPDeE=',\n",
       "   'machineType': 'n1-standard-8',\n",
       "   'acceleratorConfig': {'count': '1', 'type': 'NVIDIA_TESLA_P4'},\n",
       "   'container': {'image': 'gcr.io/mlops-dev-env/tensorflow_serving:latest-gpu',\n",
       "    'args': ['--rest_api_port=8080',\n",
       "     '--model_name=ResNet101',\n",
       "     '--model_base_path=$(AIP_STORAGE_URI)',\n",
       "     '--enable_batching',\n",
       "     '--batching_parameters_file=$(AIP_STORAGE_URI)/batching.pbtxt']},\n",
       "   'routes': {'predict': '/v1/models/ResNet101:predict',\n",
       "    'health': '/v1/models/ResNet101'}}]}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'ResNet101'\n",
    "\n",
    "client.list_model_versions(project_id, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete the specific version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/mlops-dev-env/operations/delete_ResNet101_batching_100-1597353770668',\n",
       " 'metadata': {'@type': 'type.googleapis.com/google.cloud.ml.v1.OperationMetadata',\n",
       "  'createTime': '2020-08-13T21:22:50Z',\n",
       "  'operationType': 'DELETE_VERSION',\n",
       "  'modelName': 'projects/mlops-dev-env/models/ResNet101',\n",
       "  'version': {'name': 'projects/mlops-dev-env/models/ResNet101/versions/batching_100',\n",
       "   'deploymentUri': 'gs://mlops-dev-workspace/models/resnet_serving',\n",
       "   'createTime': '2020-08-13T19:00:51Z',\n",
       "   'state': 'READY',\n",
       "   'etag': 'MbwMKzLPDeE=',\n",
       "   'machineType': 'n1-standard-8',\n",
       "   'acceleratorConfig': {'count': '1', 'type': 'NVIDIA_TESLA_P4'},\n",
       "   'container': {'image': 'gcr.io/mlops-dev-env/tensorflow_serving:latest-gpu',\n",
       "    'args': ['--rest_api_port=8080',\n",
       "     '--model_name=ResNet101',\n",
       "     '--model_base_path=$(AIP_STORAGE_URI)',\n",
       "     '--enable_batching',\n",
       "     '--batching_parameters_file=$(AIP_STORAGE_URI)/batching.pbtxt']},\n",
       "   'routes': {'predict': '/v1/models/ResNet101:predict',\n",
       "    'health': '/v1/models/ResNet101'}}}}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = 'batching_100'\n",
    "\n",
    "client.delete_model_version(project_id, model_name, model_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_model(project_id, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Walk through the `aipp_deploy.ipynb` notebook to learn how to deploy the custom serving module created in this notebook to **AI Platform Prediction** using TF Serving container image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=-1>Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at [https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions and limitations under the License.</font>"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
